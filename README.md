# Predictor Fut BR: An√°lise Preditiva do Brasileir√£o

![Python](https://img.shields.io/badge/Python-3.11-3776AB?style=for-the-badge&logo=python)
![AWS](https://img.shields.io/badge/AWS-232F3E?style=for-the-badge&logo=amazon-aws)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit)
![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=for-the-badge&logo=githubactions&logoColor=white)

## üìñ Descri√ß√£o do Projeto

Este √© um projeto completo de Machine Learning Operations (MLOps) que constr√≥i, implanta e mant√©m um sistema para prever os resultados de partidas de futebol do Campeonato Brasileiro. A solu√ß√£o vai desde a engenharia de features a partir de dados brutos at√© a entrega de uma aplica√ß√£o web interativa para o usu√°rio final, com uma pipeline de retreinamento totalmente automatizada e orientada a eventos na AWS.

O objetivo principal foi construir um produto de dados de ponta a ponta, demonstrando habilidades em Engenharia de Dados, Arquitetura de Nuvem Serverless, Automa√ß√£o de CI/CD e MLOps.

## üèõÔ∏è Arquitetura da Solu√ß√£o (v2.0)

O sistema √© projetado em uma arquitetura de microsservi√ßos e orientada a eventos, utilizando majoritariamente servi√ßos "serverless" da AWS para otimizar custos e escalabilidade.

```mermaid
graph TD
subgraph "Fluxo da Aplica√ß√£o do Usu√°rio"
User["Jornalista (Usu√°rio Final)"] --> Streamlit["Streamlit Cloud - Frontend"]
Streamlit -->|1. Faz chamada de API| AppRunnerAPI["AWS App Runner - API de Previs√£o"]
AppRunnerAPI -->|2. Carrega modelo| S3Model["Amazon S3 (/models)"]
end

    subgraph "Pipeline Autom√°tica de Retreinamento"
        S3Trigger["Amazon S3 (Novos dados em /raw)"] -->|1. Gera Evento| EventBridge["Amazon EventBridge (Gatilho)"]
        EventBridge -->|2. Inicia Pipeline| StepFunctions["AWS Step Functions (Orquestrador)"]
        StepFunctions -->|3. Job de ETL| FargateETL["AWS Fargate (data_processor.py)"]
        FargateETL -->|4. Salva Features| S3Processed["Amazon S3 (/processed)"]
        StepFunctions -->|5. Job de Treinamento| FargateTrain["AWS Fargate (model_trainer.py)"]
        FargateTrain -->|6. Salva Modelo| S3Model
        StepFunctions -->|7. Job de Deploy| FargateDeploy["AWS Fargate (deploy_api.py)"]
        FargateDeploy -->|8. Comanda Deploy| AppRunnerAPI
    end

    subgraph "Fluxo de Atualiza√ß√£o de C√≥digo (CI/CD)"
        GitHub["GitHub (Push na branch main)"] --> GHActions["GitHub Actions"]
        GHActions -->|Build & Push| ECR["Amazon ECR (Registro de Imagens)"]
        ECR -->|Imagem para Deploy| AppRunnerAPI
    end

    style User fill:#D5F5E3,stroke:#2ECC71
    style Streamlit fill:#FFD6D6,stroke:#E74C3C
    style AppRunnerAPI fill:#D6EAF8,stroke:#3498DB
    style S3Trigger fill:#FCF3CF,stroke:#F1C40F
    style S3Processed fill:#FCF3CF,stroke:#F1C40F
    style S3Model fill:#FCF3CF,stroke:#F1C40F
    style EventBridge fill:#EBDEF0,stroke:#8E44AD
    style StepFunctions fill:#EBDEF0,stroke:#8E44AD
    style FargateETL fill:#E8DAEF,stroke:#8E44AD
    style FargateTrain fill:#E8DAEF,stroke:#8E44AD
    style FargateDeploy fill:#E8DAEF,stroke:#8E44AD
    style GitHub fill:#D5D8DC,stroke:#5D6D7E
    style GHActions fill:#D5D8DC,stroke:#5D6D7E
    style ECR fill:#D5D8DC,stroke:#5D6D7E
```

**Fluxo de MLOps (Retreinamento Autom√°tico):**
1.  **Gatilho:** Um novo arquivo `.csv` com dados de uma nova rodada √© enviado para a pasta `raw/` no **Amazon S3**.
2.  **Detec√ß√£o:** O **Amazon EventBridge** detecta o novo objeto e dispara uma regra.
3.  **Orquestra√ß√£o:** A regra inicia uma pipeline no **AWS Step Functions**.
4.  **Execu√ß√£o:** A pipeline executa uma sequ√™ncia de tarefas no **AWS Fargate**:
    * **Passo 1:** Um cont√™iner processa os dados novos e antigos e salva uma nova tabela de features no S3.
    * **Passo 2:** Outro cont√™iner carrega as features, retreina o modelo de ML e salva o novo artefato do modelo no S3.
    * **Passo 3:** Um √∫ltimo cont√™iner comanda a API no **AWS App Runner** para iniciar um novo deploy.
5.  **Atualiza√ß√£o:** A API no App Runner reinicia, baixa o modelo mais recente do S3 e passa a servir as novas previs√µes.
6.  
## üìä Fonte dos Dados

Os dados utilizados neste projeto foram obtidos atrav√©s do Kaggle, no dataset **"Campeonato Brasileiro de Futebol"**, compilado por Ado Duque. O dataset cont√©m informa√ß√µes detalhadas sobre as partidas do Brasileir√£o de 2003 a 2024.

* **Link para o Dataset:** [https://www.kaggle.com/datasets/adaoduque/campeonato-brasileiro-de-futebol](https://www.kaggle.com/datasets/adaoduque/campeonato-brasileiro-de-futebol)

Foram explorados m√∫ltiplos arquivos, mas o arquivo `campeonato-brasileiro-full.csv` foi selecionado como a fonte principal de verdade para o modelo final, devido √† sua consist√™ncia e riqueza de informa√ß√µes ao longo do tempo.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.11
* **An√°lise de Dados:** Pandas, NumPy
* **Machine Learning:** Scikit-learn, XGBoost
* **Interface Web:** Streamlit
* **Servi√ßo de API:** FastAPI, Uvicorn
* **Containeriza√ß√£o:** Docker
* **Nuvem (AWS):** S3, IAM, ECR, ECS (Fargate), App Runner, Step Functions, EventBridge
* **CI/CD:** GitHub Actions
  
## üíª Ambiente de Desenvolvimento

Este projeto foi desenvolvido em um **ambiente local(Fedora - Linux)** utilizando **VS Code e Jupyter Notebooks**. A IA generativa **Gemini (Google)** foi utilizada como assistente de programa√ß√£o para acelerar o desenvolvimento, auxiliar na depura√ß√£o de erros complexos, refatorar c√≥digo para melhores pr√°ticas e para brainstorming de estrat√©gias e arquitetura do projeto.

## ‚öôÔ∏è CI/CD - Automa√ß√£o e Qualidade

O reposit√≥rio est√° configurado com uma pipeline de Integra√ß√£o Cont√≠nua (CI) utilizando **GitHub Actions**. A cada `push` ou `pull request` para a branch `main`, o workflow (`.github/workflows/ci-cd.yml`) executa automaticamente os seguintes passos:

1.  **Configura√ß√£o do Ambiente:** Prepara uma m√°quina virtual Linux com Python e instala todas as depend√™ncias do projeto.
2.  **Linting de C√≥digo:** Utiliza a ferramenta `Ruff` para verificar a qualidade do c√≥digo, garantindo que ele siga as boas pr√°ticas e esteja livre de erros comuns de sintaxe.
3.  **Teste de Build do Docker:** Executa o comando `docker build` para validar o `Dockerfile`, garantindo que a aplica√ß√£o pode ser containerizada com sucesso.

Este processo automatizado garante a integridade e a qualidade do c√≥digo, facilitando a manuten√ß√£o e futuras implanta√ß√µes.

## üìÇ Estrutura do Projeto

```
predictor_fut_br/
‚îú‚îÄ‚îÄ .github/              # Workflows do GitHub Actions
‚îú‚îÄ‚îÄ api/                  # C√≥digo da API (main.py, Dockerfile)
‚îú‚îÄ‚îÄ frontend/             # Aplica√ß√£o Streamlit (app.py, requirements)
‚îú‚îÄ‚îÄ ml_jobs/              # Scripts de ETL e Treinamento (data_processor.py, etc., Dockerfile)
‚îú‚îÄ‚îÄ notebooks/            # An√°lise explorat√≥ria e prototipagem inicial
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt      # Depend√™ncias da API
```

## üöÄ Como Executar

### Pr√©-requisitos
* Python 3.11+
* Conta na AWS com AWS CLI configurado
* Docker Desktop

### Backend (API e Pipeline)
A infraestrutura do backend √© provisionada e gerenciada na AWS. As instru√ß√µes de deploy e automa√ß√£o est√£o contidas na l√≥gica do projeto e s√£o orquestradas pelo Step Functions.

### Frontend (Aplica√ß√£o Streamlit)
1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [URL_DO_SEU_REPO]
    cd predictor_fut_br
    ```
2.  **Crie e ative um ambiente virtual:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Mac/Linux
    .\venv\Scripts\activate    # Windows
    ```
3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r frontend/requirements-frontend.txt
    ```
4.  **Configure o app.py:**
    * Abra o arquivo `frontend/app.py` e substitua os placeholders `SEU-NOME-DE-BUCKET-AQUI` e `SUA_URL_DA_API_APPRUNNER_AQUI` pelos seus valores.
5.  **Execute a aplica√ß√£o:**
    * *Importante: O servi√ßo da API no AWS App Runner deve estar no estado "Running" (reative-o se estiver pausado).*
    ```bash
    streamlit run frontend/app.py
    ```

7.  **Teste a API:**
    Abra seu navegador e acesse `http://127.0.0.1:8000/docs` para interagir com a API e fazer previs√µes.

### üîß Usando o Gerador de Features

O projeto inclui uma ferramenta de linha de comando, `gerar_features.py`, para automatizar a cria√ß√£o do JSON de features para qualquer confronto.

1.  **Abra um novo terminal** na pasta raiz do projeto.
2.  **Execute o script** passando o nome do mandante e do visitante entre aspas. O script √© tolerante a mai√∫sculas/min√∫sculas.

    **Exemplo:**
    ```bash
    python gerar_features.py "Palmeiras" "Corinthians"
    ```

3.  **O script ir√° gerar e imprimir o JSON formatado**, pronto para ser copiado e colado no corpo da requisi√ß√£o do endpoint `/predict` na documenta√ß√£o interativa da API.


## üß≠ Jornada do Projeto e Decis√µes Estrat√©gicas

Este projeto foi desenvolvido em duas grandes fases, refletindo a evolu√ß√£o de um prot√≥tipo local para um sistema de produ√ß√£o automatizado na nuvem.

#### **Vers√£o 1.0**
A primeira etapa focou em provar a viabilidade do modelo. O trabalho incluiu:

* **An√°lise Explorat√≥ria (EDA):** Utilizando Jupyter Notebooks para entender os dados, identificar problemas de qualidade e pivotar a estrat√©gia de focar no dataset full.csv ap√≥s descobrir inconsist√™ncias em outras fontes.
* **Engenharia de Features:** Cria√ß√£o de features de "forma" (performance recente) e "contexto" (t√°tica, rivalidade).
* **Modelo e API Locais:** Treinamento de um modelo XGBoost e sua exposi√ß√£o atrav√©s de uma API RESTful com FastAPI, tudo rodando em um ambiente local containerizado com Docker.

Esta fase validou o modelo e a l√≥gica de neg√≥cio, resultando em um servi√ßo funcional, por√©m est√°tico e com implanta√ß√£o manual.

#### **Vers√£o 2.0**

A segunda fase elevou o projeto a um n√≠vel profissional, com o objetivo de criar um sistema din√¢mico, resiliente e que se atualiza sozinho.

* **Arquitetura Serverless:** O sistema foi redesenhado para a AWS, utilizando servi√ßos gerenciados como App Runner, Fargate, S3 e IAM para criar uma infraestrutura escal√°vel e de baixo custo.
* **Modulariza√ß√£o:** O c√≥digo do notebook foi refatorado em scripts Python independentes e containerizados (data_processor.py, model_trainer.py), prontos para execu√ß√£o como jobs.
* **Pipeline de Orquestra√ß√£o:** Foi implementada uma pipeline completa no AWS Step Functions que, em sequ√™ncia, processa novos dados, retreina o modelo e comanda o deploy da API atualizada.
* **Automa√ß√£o com Gatilhos:** O Amazon EventBridge foi configurado para "observar" o S3 e disparar toda a pipeline de retreinamento automaticamente quando novos dados chegam, eliminando qualquer interven√ß√£o manual.
* **Entrega de Valor ao Usu√°rio:** Uma interface amig√°vel foi criada com Streamlit, conectando todo o poder do backend a um produto final simples e intuitivo para o usu√°rio.

Esta transi√ß√£o demonstra o ciclo de vida completo de um produto de dados, desde a concep√ß√£o e prototipagem at√© a automa√ß√£o e manuten√ß√£o em um ambiente de produ√ß√£o na nuvem.

#### **O Caminho Final e Principais Aprendizados**
A nova estrat√©gia focou em extrair o m√°ximo valor da fonte de dados mais confi√°vel. Isso levou √† cria√ß√£o de um sistema de features robusto, baseado em dois pilares: a **"forma"** recente das equipes (performance baseada em resultados) e o **"contexto"** do jogo (fatores t√°ticos e circunstanciais).

Esta jornada refor√ßou aprendizados cruciais:
* **A qualidade dos dados supera a quantidade:** √â melhor ter um modelo baseado em features consistentes e confi√°veis do que um modelo baseado em dados "detalhados", mas de baixa qualidade.
* **Adaptabilidade √© chave:** A capacidade de pivotar uma estrat√©gia com base nas evid√™ncias encontradas na fase de explora√ß√£o √© fundamental para o sucesso de um projeto de dados.
* **Engenharia de Features √© o cora√ß√£o do projeto:** O valor do modelo final foi derivado diretamente da habilidade de traduzir conceitos do futebol (forma, t√°tica, rivalidade) em representa√ß√µes matem√°ticas que a IA pudesse entender.

## üîÆ Pr√≥ximos Passos

* **Hyperparameter Tuning:** Otimizar os par√¢metros do modelo XGBoost para extrair o m√°ximo de acur√°cia.
* **Expandir a API:** Criar novos endpoints, como um que retorne as probabilidades de cada resultado (`/predict_proba`).
* **Pipeline de CI/CD:** Automatizar os testes e o deployment de novas vers√µes da API usando ferramentas como GitHub Actions.