# Guia de Implementa√ß√£o: Pipeline MLOps Preditiva na AWS

Bem-vindo ao guia de implementa√ß√£o do projeto Predictor Fut BR! Este documento detalha o passo a passo para construir e implantar a arquitetura completa na sua pr√≥pria conta da AWS.

## üìã Pr√©-requisitos
Antes de come√ßar, garanta que voc√™ tenha:
1. Uma conta na AWS com acesso de administrador.

2. AWS CLI instalado e configurado em sua m√°quina local.

3. Docker Desktop instalado e rodando.

4. Python 3.11+ instalado.

5. Git instalado.

## ‚öôÔ∏è Fase 0: Configura√ß√£o Inicial do Projeto
Nesta fase, preparamos o ambiente local e as configura√ß√µes.

1. **Clonar o Reposit√≥rio:**
   ```bash
    git clone https://github.com/Bolinhx/predictor_fut_br.git
    cd predictor_fut_br
    ```
2. **Configurar Vari√°veis de Ambiente:**
   - Renomeie o arquivo .env.example para .env.
   - Abra o arquivo .env e preencha todas as vari√°veis com os valores da sua conta e recursos que ser√£o criados.
3. **Criar Ambiente Virtual e Instalar Depend√™ncias:**
   ```bash
   python -m venv venv
    source venv/bin/activate  # ou .\\venv\\Scripts\\activate no Windows
    pip install -r requirements.txt
    pip install -r ml_jobs/requirements-jobs.txt
    pip install -r frontend/requirements-frontend.txt
    ```

## üèóÔ∏è Fase 1: Funda√ß√£o da Infraestrutura na AWS

Nesta fase, criamos os recursos de base que nosso sistema precisar√° para armazenar dados e c√≥digo. N√£o vamos rodar nada ainda, apenas preparar o terreno.

### 1. IAM - Criando um Usu√°rio para Automa√ß√£o

Nunca usamos a conta "root" (principal) para tarefas do dia a dia ou para automa√ß√£o. O primeiro passo √© criar um usu√°rio dedicado com permiss√µes espec√≠ficas, seguindo o **princ√≠pio do menor privil√©gio**.

1.  Acesse o **Console da AWS** e procure pelo servi√ßo **IAM**.
2.  No menu lateral, clique em **Users** (Usu√°rios) e depois em **Create user**.
3.  **User details:**
    * **User name:** D√™ um nome para o usu√°rio, por exemplo: `predictor-project-user`.
    * **N√ÉO** marque a op√ß√£o "Provide user access to the AWS Management Console". Este usu√°rio ser√° usado apenas por programas (acesso program√°tico).
4.  **Set permissions:**
    * Selecione a op√ß√£o **Attach policies directly**.
    * Na barra de busca, procure e marque as seguintes pol√≠ticas gerenciadas pela AWS. Elas dar√£o as permiss√µes necess√°rias para nossos servi√ßos interagirem:
        * `AmazonS3FullAccess`
        * `AmazonEC2ContainerRegistryFullAccess` (ou `AmazonECRFullAccess`)
        * `AWSAppRunnerFullAccess`
        * `AmazonECS_FullAccess`
        * `AWSStepFunctionsFullAccess`
5.  **Review and create:**
    * Revise as informa√ß√µes e clique em **Create user**.
6.  **Salve as Credenciais (Etapa Cr√≠tica):**
    * Na lista de usu√°rios, clique no nome do usu√°rio que voc√™ acabou de criar.
    * V√° para a aba **Security credentials**.
    * Role para baixo at√© **Access keys** e clique em **Create access key**.
    * Selecione **Command Line Interface (CLI)**, marque a caixa de confirma√ß√£o e clique em **Next**.
    * Clique em **Create access key**.
    * **IMPORTANTE:** Copie e salve o `Access key ID` e a `Secret access key` em um local seguro. Esta √© a **√∫nica vez** que a chave secreta ser√° exibida.
7.  **Configure a AWS CLI:**
    * Abra seu terminal e configure o perfil de acesso com as chaves que voc√™ acabou de salvar:
        ```bash
        aws configure
        # Preencha com seu Access Key ID, Secret Access Key, uma regi√£o padr√£o (ex: us-east-1) e o formato de sa√≠da (json).
        ```

### 2. S3 - Criando nosso Bucket de Armazenamento (Data Lake)

O Amazon S3 ser√° o cora√ß√£o do nosso armazenamento, guardando os dados brutos, as features processadas e os modelos treinados.

1.  No console da AWS, procure e v√° para o servi√ßo **S3**.
2.  Clique em **Create bucket**.
3.  **General configuration:**
    * **Bucket name:** D√™ um nome **globalmente √∫nico**. Use o padr√£o do seu arquivo `.env`: `predictor-fut-br-data-SEU-NOME-UNICO`.
    * **AWS Region:** Selecione a mesma regi√£o que voc√™ configurou no seu AWS CLI.
4.  **Block Public Access settings:**
    * Mantenha a op√ß√£o **Block all public access** LIGADA (marcada). Nossos dados s√£o privados.
5.  **Bucket Versioning:**
    * Selecione **Enable**. Isso nos protege contra exclus√µes acidentais.
6.  **Default encryption:**
    * Selecione **Enable**. Garanta que a op√ß√£o `Amazon S3-managed keys (SSE-S3)` esteja selecionada (esta op√ß√£o n√£o tem custo).
7.  Clique em **Create bucket**.
8.  **Crie as Pastas:**
    * Dentro do bucket, clique em **Create folder** e crie as tr√™s pastas necess√°rias: `raw`, `processed` e `models`.
9.  **Fa√ßa o Upload do Dado Inicial:**
    * Navegue at√© a pasta `raw` e fa√ßa o upload do arquivo `campeonato-brasileiro-full.csv` do seu computador.
     
   <img width="2111" height="708" alt="S3 - Raiz" src="https://github.com/user-attachments/assets/11a625dc-de39-463a-a276-26fd0c7a6170" />



### 3. ECR - Criando os Reposit√≥rios para as Imagens Docker

O Elastic Container Registry (ECR) √© o nosso "Docker Hub" privado na AWS, onde guardaremos as imagens prontas para serem usadas pelo App Runner e Fargate.

1.  No console da AWS, procure e v√° para o servi√ßo **Elastic Container Registry (ECR)**.
2.  Clique em **Create repository**.
3.  Configure o primeiro reposit√≥rio:
    * **Visibility settings:** `Private`
    * **Repository name:** Use o nome que est√° no seu arquivo `.env`: `prediction-api` (ou o que voc√™ definiu).
    * Clique em **Create repository**.
4.  Repita o processo para criar o segundo reposit√≥rio com o nome `ml-jobs`.
   
   <img width="2116" height="822" alt="ECR-Repositorys" src="https://github.com/user-attachments/assets/df06fc01-99a4-466b-bd66-a919bfcef2d9" />

   

## üöÄ Fase 2: Deploy Manual e Valida√ß√£o

Nesta fase, vamos colocar nosso c√≥digo para rodar na nuvem pela primeira vez. O objetivo √© validar cada componente de forma isolada (as imagens Docker, as permiss√µes, os servi√ßos) antes de conect√°-los com a automa√ß√£o.

### 1. Build e Push das Imagens Docker

Nossas "receitas" (`Dockerfile`) est√£o prontas. Agora vamos us√°-las para construir as imagens e envi√°-las para nosso registro privado na AWS (ECR).

1.  **Autenticar o Docker no ECR:**
    No seu terminal, execute o comando abaixo, substituindo `sua-regiao` e `SEU_ID_DE_CONTA` pelos seus valores. A forma mais f√°cil de obter o comando exato √© ir ao console do **ECR**, clicar em um dos reposit√≥rios e no bot√£o **"View push commands"**.
    ```bash
    aws ecr get-login-password --region sua-regiao | docker login --username AWS --password-stdin SEU_ID_DE_CONTA.dkr.sua-regiao.amazonaws.com
    ```
    Voc√™ deve ver a mensagem "Login Succeeded".

2.  **Construir, Marcar (Tag) e Enviar as Imagens:**
    Execute os seguintes comandos na raiz do seu projeto. Lembre-se de preencher as vari√°veis no seu arquivo `.env` primeiro, pois os comandos usam `$(grep ...)` para l√™-las.

    * **Para a API de Predi√ß√£o:**
        ```bash
        # Obter a URI do reposit√≥rio a partir do seu arquivo .env
        ECR_URI_API=$(grep ECR_REPO_API .env | cut -d '=' -f2 | tr -d '"')
        AWS_ACCOUNT_ID=$(grep AWS_ACCOUNT_ID .env | cut -d '=' -f2 | tr -d '"')
        AWS_REGION=$(grep AWS_REGION .env | cut -d '=' -f2 | tr -d '"')
        
        # Construir, marcar e enviar
        docker build -t $ECR_URI_API -f api/Dockerfile .
        docker tag $ECR_URI_API:latest $AWS_ACCOUNT_ID.dkr.ecr.$AWS_[REGION.amazonaws.com/$ECR_URI_API:latest](https://REGION.amazonaws.com/$ECR_URI_API:latest)
        docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_[REGION.amazonaws.com/$ECR_URI_API:latest](https://REGION.amazonaws.com/$ECR_URI_API:latest)
        ```

    * **Para os Jobs de ML:**
        ```bash
        # Obter a URI do reposit√≥rio a partir do seu arquivo .env
        ECR_URI_JOBS=$(grep ECR_REPO_JOBS .env | cut -d '=' -f2 | tr -d '"')
        
        # Construir, marcar e enviar
        docker build -t $ECR_URI_JOBS -f ml_jobs/Dockerfile .
        docker tag $ECR_URI_JOBS:latest $AWS_ACCOUNT_ID.dkr.ecr.$AWS_[REGION.amazonaws.com/$ECR_URI_JOBS:latest](https://REGION.amazonaws.com/$ECR_URI_JOBS:latest)
        docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_[REGION.amazonaws.com/$ECR_URI_JOBS:latest](https://REGION.amazonaws.com/$ECR_URI_JOBS:latest)
        ```

### 2. Deploy da API no AWS App Runner

Com a imagem da API no ECR, vamos coloc√°-la no ar.

1.  Acesse o servi√ßo **AWS App Runner** no console e clique em **Create service**.
2.  **Source and deployment:**
    * **Source:** `Container registry`
    * **Container image registry:** `Amazon ECR`
    * **Container image URI:** Clique em **Browse** e selecione a imagem da sua API (ex: `prediction-api`).
3.  **Configure service:**
    * **Service name:** `prediction-api`.
    * **Virtual CPU & memory:** Para testes, comece com `1 vCPU` e `2 GB`. Se a aplica√ß√£o falhar ao iniciar, pode ser necess√°rio aumentar a mem√≥ria para `3 GB`.
    * **Port:** `80`.
4.  **Security (Etapa Crucial):**
    * Na se√ß√£o **Security**, clique em **Edit**.
    * **Instance role:** Para que a API possa acessar o S3, precisamos de uma permiss√£o. Crie uma nova IAM Role seguindo estes passos:
        * V√° para o **IAM** -> **Roles** -> **Create role**.
        * **Trusted entity type:** `Custom trust policy`. Cole o JSON:
            ```json
            {
                "Version": "2012-10-17",
                "Statement": [{
                    "Effect": "Allow",
                    "Principal": {"Service": "tasks.apprunner.amazonaws.com"},
                    "Action": "sts:AssumeRole"
                }]
            }
            ```
        * **Permissions:** Anexe a pol√≠tica gerenciada pela AWS `AmazonS3ReadOnlyAccess`.
        * **Role name:** `AppRunnerInstanceRole`.
        * Volte para a configura√ß√£o do App Runner, atualize a lista e selecione a `AppRunnerInstanceRole` que voc√™ acabou de criar.
5.  Clique em **Create & deploy**.

#### üö® Solu√ß√£o de Problemas Comuns no App Runner
* **Erro `Failed to create...`:** Geralmente √© um problema de tempo ou mem√≥ria.
    * **`Health check failed`:** A aplica√ß√£o demorou muito para iniciar. Edite o servi√ßo, v√° em **Health check** e aumente os valores de **Timeout** (para `20s`) e **Interval** (para `25s`).
    * **`Unable to locate credentials`:** A **Instance role** n√£o foi criada ou anexada corretamente. Verifique o passo 4.

### 3. Execu√ß√£o Manual dos Jobs no Fargate

Vamos validar que nossos scripts de processamento e treinamento rodam na nuvem.

1.  **Crie as Permiss√µes (IAM Roles):** Nossa tarefa precisa de duas "credenciais":
    * **Task Execution Role:** Permiss√£o para o Fargate buscar a imagem no ECR. Geralmente a role `ecsTaskExecutionRole` j√° existe na conta.
    * **Task Role:** Permiss√£o para o **nosso c√≥digo** acessar outros servi√ßos.
        * V√° para **IAM** -> **Roles** -> **Create role**.
        * **Trusted entity:** `AWS service` -> **Use case:** `Elastic Container Service Task`.
        * **Permissions:** Anexe as pol√≠ticas `AmazonS3FullAccess` e `AWSAppRunnerFullAccess`.
        * **Role name:** `ECSTaskS3AppRunnerRole`.

2.  **Crie a Defini√ß√£o da Tarefa (Task Definition):**
    * V√° para **Amazon ECS** -> **Task Definitions** -> **Create new task definition**.
    * **Task definition family:** `ml-job-task-family`.
    * **Launch type:** `AWS Fargate`.
    * **Task role:** Selecione a `ECSTaskS3AppRunnerRole` que acabamos de criar.
    * **Task execution role:** Selecione a `ecsTaskExecutionRole`.
    * **Container details:**
        * **Name:** `ml-jobs-container`.
        * **Image URI:** Cole a URI da sua imagem `ml-jobs` do ECR.
    * Clique em **Create**.

3.  **Execute a Tarefa Manualmente:**
    * V√° para **Amazon ECS** -> **Clusters** e selecione o cluster `default` (ou crie um novo do tipo "Networking only" se n√£o existir).
    * Clique na aba **Tasks** -> **Run new task**.
    * **Launch type:** `FARGATE`.
    * **Task definition:** Selecione a `ml-job-task-family`.
    * **Networking:** Garanta que uma VPC e Subnets estejam selecionadas e que **Public IP** esteja **ENABLED**.
    * **Container Overrides:** Expanda a se√ß√£o e, no campo **Command**, cole o comando para o primeiro script (separado por v√≠rgulas):
        ```text
        python,data_processor.py,s3://SEU-BUCKET/raw/campeonato-brasileiro-full.csv,s3://SEU-BUCKET/raw/campeonato-brasileiro-full.csv,s3://SEU-BUCKET/processed/features.parquet
        ```
        *(Nota: Para este teste, usamos o mesmo arquivo como hist√≥rico e "novo", o que funciona para valida√ß√£o).*
    * Clique em **Run task**.

#### üö® Solu√ß√£o de Problemas Comuns no Fargate
* **Erro `iam:PassRole`:** O servi√ßo que est√° executando a tarefa (Step Functions, no futuro) precisa de permiss√£o para "entregar" a `Task Role` √† tarefa.
* **Erro `PermissionError: Forbidden`:** A `Task Role` (`ECSTaskS3AppRunnerRole`) n√£o tem a permiss√£o necess√°ria (ex: `AmazonS3FullAccess`).
* **Erro `FileNotFoundError: fsspec`:** A imagem Docker est√° sem as bibliotecas `fsspec` e `s3fs`. Adicione-as ao `ml_jobs/requirements-jobs.txt`.


## ü§ñ Fase 3: Automa√ß√£o com a Pipeline MLOps

Com os componentes validados, vamos conectar tudo em um fluxo de trabalho 100% autom√°tico. Usaremos o **AWS Step Functions** como o "maestro" que orquestra as tarefas e o **Amazon EventBridge** como o "sensor" que dispara a pipeline.

### 1. Cria√ß√£o da Pipeline no Step Functions (O Maestro)

A State Machine no Step Functions √© o nosso fluxograma execut√°vel.

1.  Acesse o servi√ßo **Step Functions** no console e clique em **Create state machine**.
2.  Mantenha as op√ß√µes **Design your workflow visually** e **Type: Standard**.
3.  Voc√™ estar√° no **Workflow Studio**. Na barra de "Actions" √† esquerda, encontre e arraste a a√ß√£o **ECS RunTask** para o fluxograma tr√™s vezes, uma abaixo da outra, para criar uma sequ√™ncia de tr√™s passos.
4.  **Configure cada passo** clicando nele e preenchendo as informa√ß√µes no painel direito:

    ---
    #### **Passo 1: Processar Novos Dados**
    * **Aba "Configuration":**
        * **State name:** `ProcessarNovosDados`
        * **Marque a caixa:** `Wait for task to complete` (essencial para a execu√ß√£o em sequ√™ncia).
    * **Aba "Arguments & Output":**
        * No campo **Arguments**, cole o JSON abaixo, substituindo os placeholders com seus valores do arquivo `.env`.
            ```json
            {
              "LaunchType": "FARGATE",
              "Cluster": "predictor-fut-br-cluster",
              "TaskDefinition": "ml-job-task-family",
              "NetworkConfiguration": {
                "AwsvpcConfiguration": {
                  "Subnets": [
                    "SUA_SUBNET_ID_AQUI"
                  ],
                  "AssignPublicIp": "ENABLED"
                }
              },
              "Overrides": {
                "ContainerOverrides": [
                  {
                    "Name": "ml-jobs-container",
                    "Command": [
                      "python",
                      "data_processor.py",
                      "s3://SEU_BUCKET_NAME/raw/campeonato-brasileiro-full.csv",
                      "s3://SEU_BUCKET_NAME/raw/campeonato-brasileiro-full.csv",
                      "s3://SEU_BUCKET_NAME/processed/features.parquet"
                    ]
                  }
                ]
              }
            }
            ```

    ---
    #### **Passo 2: Treinar Novo Modelo**
    * **Aba "Configuration":**
        * **State name:** `TreinarNovoModelo`
        * **Marque a caixa:** `Wait for task to complete`.
    * **Aba "Arguments & Output":**
        * No campo **Arguments**, cole o mesmo JSON, alterando apenas o `Command`:
            ```json
            {
              "LaunchType": "FARGATE",
              "Cluster": "predictor-fut-br-cluster",
              "TaskDefinition": "ml-job-task-family",
              "NetworkConfiguration": {
                "AwsvpcConfiguration": {
                  "Subnets": [
                    "SUA_SUBNET_ID_AQUI"
                  ],
                  "AssignPublicIp": "ENABLED"
                }
              },
              "Overrides": {
                "ContainerOverrides": [
                  {
                    "Name": "ml-jobs-container",
                    "Command": [
                      "python",
                      "model_trainer.py",
                      "s3://SEU_BUCKET_NAME/processed/features.parquet",
                      "s3://SEU_BUCKET_NAME/models/modelo_final.joblib"
                    ]
                  }
                ]
              }
            }
            ```

    ---
    #### **Passo 3: Implantar Nova API**
    * **Aba "Configuration":**
        * **State name:** `ImplantarNovaAPI`
        * **Marque a caixa:** `Wait for task to complete`.
    * **Aba "Arguments & Output":**
        * No campo **Arguments**, cole o mesmo JSON, alterando apenas o `Command`:
            ```json
            {
              "LaunchType": "FARGATE",
              "Cluster": "predictor-fut-br-cluster",
              "TaskDefinition": "ml-job-task-family",
              "NetworkConfiguration": {
                "AwsvpcConfiguration": {
                  "Subnets": [
                    "SUA_SUBNET_ID_AQUI"
                  ],
                  "AssignPublicIp": "ENABLED"
                }
              },
              "Overrides": {
                "ContainerOverrides": [
                  {
                    "Name": "ml-jobs-container",
                    "Command": [
                      "python",
                      "deploy_api.py",
                      "SEU_APP_RUNNER_SERVICE_ARN_AQUI"
                    ]
                  }
                ]
              }
            }
            ```

5.  Clique em **Next**. Na tela de revis√£o, d√™ um nome √† sua pipeline (ex: `Fut-BR-Retraining-Pipeline`) e selecione **Create new IAM role**. Clique em **Create state machine**.

> üì∏ **Sugest√£o de Print:** Tire um print do **Graph inspector** do Step Functions mostrando a execu√ß√£o bem-sucedida com todos os tr√™s passos em verde.

#### üö® Solu√ß√£o de Problemas Comuns no Step Functions
* **Erro `AccessDeniedException: ... is not authorized to perform: ecs:RunTask`:** A "role" criada automaticamente para o Step Functions n√£o tem permiss√£o para iniciar tarefas no ECS.
    * **Solu√ß√£o:** V√° para **IAM** -> **Roles** e encontre a role do seu Step Function. Clique em **Add permissions** -> **Create inline policy** e adicione a seguinte pol√≠tica JSON:
        ```json
        {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": ["ecs:RunTask", "ecs:StopTask", "ecs:DescribeTasks"],
                    "Resource": "*"
                }
            ]
        }
        ```
* **Erro `AccessDeniedException: ... is not authorized to perform: iam:PassRole`:** O Step Functions n√£o tem permiss√£o para "entregar" as credenciais (`ECSTaskS3AppRunnerRole` e `ecsTaskExecutionRole`) para a tarefa Fargate.
    * **Solu√ß√£o:** Na mesma "role" do Step Functions, crie outra pol√≠tica inline com o seguinte JSON, substituindo os ARNs pelos da sua conta:
        ```json
        {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Effect": "Allow",
                    "Action": "iam:PassRole",
                    "Resource": [
                        "ARN_DA_SUA_ROLE_ECSTaskS3AppRunnerRole_AQUI",
                        "ARN_DA_SUA_ROLE_ecsTaskExecutionRole_AQUI"
                    ],
                    "Condition": {
                        "StringEquals": { "iam:PassedToService": "ecs-tasks.amazonaws.com" }
                    }
                }
            ]
        }
        ```

### 2. Cria√ß√£o do Gatilho no EventBridge (O Sensor)

Este servi√ßo ir√° "observar" nosso S3 e iniciar a pipeline automaticamente.

1.  Acesse o servi√ßo **Amazon EventBridge** e clique em **Create rule**.
2.  **Name:** `Trigger-Retraining-On-New-Data`.
3.  **Event bus:** `default`.
4.  **Rule type:** `Rule with an event pattern`.
5.  **Event pattern:** Selecione **Custom pattern (JSON editor)** e cole o seguinte JSON, substituindo o nome do seu bucket:
    ```json
    {
      "source": ["aws.s3"],
      "detail-type": ["Object Created"],
      "detail": {
        "bucket": {
          "name": ["SEU_BUCKET_NAME"]
        },
        "object": {
          "key": [{
            "prefix": "raw/"
          }, {
            "suffix": ".csv"
          }]
        }
      }
    }
    ```
6.  **Select a target:**
    * **Target types:** `AWS service`.
    * **Select a target:** `Step Functions state machine`.
    * **State machine:** `Fut-BR-Retraining-Pipeline`.
    * **Execution role:** `Create a new role for this specific resource`.
7.  Clique em **Create rule**.

#### üö® Solu√ß√£o de Problemas Comuns no EventBridge
* **A pipeline n√£o inicia ao subir um arquivo:** O S3 n√£o tem permiss√£o para enviar notifica√ß√µes ao EventBridge.
    * **Solu√ß√£o:** V√° para o seu **Bucket S3** -> **Properties** -> **Event Notifications**. Encontre a op√ß√£o **"Send notifications to Amazon EventBridge"**, clique em **Edit** e mude para **On**.


## üñ•Ô∏è Fase 4: Frontend com Streamlit

Com todo o nosso sistema de backend e MLOps funcionando nos bastidores, chegou a hora de construir a interface que o nosso usu√°rio final (o jornalista) ir√° usar. Vamos criar uma aplica√ß√£o web simples e funcional usando **Streamlit**, uma biblioteca Python que facilita a cria√ß√£o de interfaces para projetos de dados.

### 1. Teste Local da Aplica√ß√£o

Antes de colocar o frontend online, √© essencial test√°-lo em sua m√°quina para garantir que ele consegue se comunicar com a API na AWS.

1.  **Reative a API no App Runner:**
    * V√° para o console do **AWS App Runner** e, no seu servi√ßo `prediction-api`, clique em **"Resume"**. Aguarde o status mudar para **"Running"**.

2.  **Instale as Depend√™ncias do Frontend:**
    * No seu terminal, na raiz do projeto (com o ambiente virtual `venv` ativado), execute:
        ```bash
        pip install -r frontend/requirements-frontend.txt
        ```

3.  **Preencha as Vari√°veis de Ambiente:**
    * Certifique-se de que o seu arquivo `.env` na raiz do projeto est√° preenchido com os valores corretos para `S3_BUCKET_NAME` e `APP_RUNNER_SERVICE_URL`. O script local ler√° essas vari√°veis.

4.  **Execute a Aplica√ß√£o Streamlit:**
    * No mesmo terminal, execute o comando:
        ```bash
        streamlit run frontend/app.py
        ```

5.  Seu navegador deve abrir automaticamente com a aplica√ß√£o rodando. Teste a sele√ß√£o de times e clique no bot√£o "Analisar e Prever Resultado" para confirmar que a comunica√ß√£o com a API est√° funcionando.

> üì∏ **Sugest√£o de Print:** Tire um print da aplica√ß√£o Streamlit rodando localmente com uma previs√£o bem-sucedida sendo exibida na tela.

### 2. Deploy na Streamlit Community Cloud

Agora, vamos hospedar nossa aplica√ß√£o de gra√ßa, com um link p√∫blico, usando a plataforma da pr√≥pria Streamlit.

1.  **Crie uma Conta:**
    * V√° para [share.streamlit.io](https://share.streamlit.io) e crie uma conta, conectando-a com seu perfil do GitHub. √â um processo r√°pido e gratuito.

2.  **Fa√ßa um √öltimo Commit:**
    * Garanta que todo o seu c√≥digo, incluindo a pasta `frontend` e o `IMPLEMENTATION_GUIDE.md`, esteja atualizado no seu reposit√≥rio do GitHub.
        ```bash
        git add .
        git commit -m "docs: Finaliza guia de implementa√ß√£o"
        git push origin main
        ```

3.  **Crie a Nova Aplica√ß√£o no Streamlit Cloud:**
    * No seu dashboard do Streamlit, clique em **"New app"**.
    * **Repository:** Selecione o seu reposit√≥rio `predictor_fut_br`.
    * **Branch:** Selecione `main`.
    * **Main file path:** Digite o caminho para o arquivo principal: `frontend/app.py`.
    * **App URL:** D√™ um nome customizado para a sua URL (ex: `predictor-fut-br`).

4.  **Configure os "Secrets" (Etapa Crucial):**
    * Antes de clicar em "Deploy", clique no link **"Advanced settings..."**.
    * Na se√ß√£o **Secrets**, voc√™ precisa adicionar as mesmas vari√°veis de ambiente do seu arquivo `.env` para que a aplica√ß√£o na nuvem possa se conectar √† AWS. Adicione os seguintes "secrets":
        * `AWS_ACCESS_KEY_ID`: Cole a chave de acesso do seu usu√°rio IAM `predictor-project-user`.
        * `AWS_SECRET_ACCESS_KEY`: Cole a chave secreta do seu usu√°rio IAM.
        * `S3_BUCKET_NAME`: Cole o nome do seu bucket S3.
        * `APP_RUNNER_SERVICE_URL`: Cole a URL da sua API no App Runner.
    * **Importante:** A biblioteca `python-dotenv` n√£o funciona no Streamlit Cloud; ele injeta os "secrets" como vari√°veis de ambiente, e nosso c√≥digo j√° est√° preparado para ler isso.

5.  **Fa√ßa o Deploy:**
    * Clique no bot√£o **"Deploy!"**. O Streamlit ir√° construir o ambiente e colocar sua aplica√ß√£o no ar.

> üì∏ **Sugest√£o de Print:** Tire um print da sua aplica√ß√£o rodando online, no link p√∫blico fornecido pelo Streamlit Cloud. E outro print da tela de configura√ß√£o de "Secrets" no Streamlit Cloud, mostrando as chaves que voc√™ adicionou (censure os valores das chaves de acesso).

#### üö® Solu√ß√£o de Problemas Comuns no Streamlit
* **Erro de Credenciais na Nuvem:** Se a aplica√ß√£o online n√£o conseguir acessar o S3, o problema quase sempre est√° nos "Secrets". Verifique se os nomes das vari√°veis e seus valores foram copiados corretamente.
* **`ModuleNotFoundError`:** O Streamlit n√£o encontrou uma biblioteca. Verifique se o arquivo `frontend/requirements-frontend.txt` est√° correto e atualizado no GitHub.

## üßπ Fase 5: Limpeza dos Recursos

Ap√≥s concluir o projeto e a documenta√ß√£o, √© crucial remover todos os recursos criados na AWS para garantir que n√£o haja cobran√ßas futuras. Siga esta lista de verifica√ß√£o na **ordem exata** para evitar erros de depend√™ncia (onde n√£o √© poss√≠vel excluir um recurso porque outro ainda depende dele).

### Checklist de Desmontagem

1.  **Pausar e Deletar o Servi√ßo do App Runner:**
    * V√° para o console do **AWS App Runner**.
    * Selecione o servi√ßo `prediction-api`.
    * Se estiver com o status "Running", clique em **"Actions"** -> **"Pause"**. Aguarde o status mudar para "Paused".
    * Com o servi√ßo pausado, clique em **"Actions"** -> **"Delete"**. Confirme a exclus√£o.

2.  **Deletar a Regra do EventBridge:**
    * V√° para o console do **Amazon EventBridge**.
    * No menu lateral, clique em **Rules**.
    * Selecione a regra `Trigger-Retraining-On-New-Data` e clique em **"Delete"**. Confirme a exclus√£o.

3.  **Deletar a Pipeline do Step Functions:**
    * V√° para o console do **AWS Step Functions**.
    * No menu lateral, clique em **State machines**.
    * Selecione a pipeline `Fut-BR-Retraining-Pipeline` e clique em **"Delete"**. Confirme a exclus√£o.

4.  **Desregistrar a Defini√ß√£o de Tarefa do ECS:**
    * V√° para o console do **Amazon ECS**.
    * No menu lateral, clique em **Task Definitions**.
    * Selecione a fam√≠lia `ml-job-task-family`.
    * Para cada revis√£o na lista (ex: `:1`, `:2`), clique nela, v√° em **"Actions"** -> **"Deregister"**.

5.  **Deletar o Cluster do ECS:**
    * Ainda no console do ECS, clique em **Clusters**.
    * Selecione o seu cluster `predictor-fut-br-cluster`.
    * Clique em **"Delete Cluster"**. Confirme a exclus√£o.

6.  **Deletar Imagens e Reposit√≥rios do ECR:**
    * V√° para o console do **Amazon ECR**.
    * Clique em cada um dos seus reposit√≥rios (`prediction-api` e `ml-jobs`).
    * Dentro de cada reposit√≥rio, selecione todas as imagens listadas e clique em **"Delete"**.
    * Depois que os reposit√≥rios estiverem vazios, volte para a lista principal, selecione-os e clique em **"Delete"**.

7.  **Esvaziar e Deletar o Bucket S3:**
    * V√° para o console do **Amazon S3**.
    * Selecione o seu bucket `predictor-fut-br-data-...`.
    * Clique no bot√£o **"Empty"**. O S3 o guiar√° pelo processo de confirma√ß√£o para apagar todos os objetos e vers√µes.
    * Depois que o bucket estiver vazio, volte para a lista de buckets, selecione-o e clique em **"Delete"**.

8.  **Deletar as IAM Roles:**
    * V√° para o console do **IAM** -> **Roles**.
    * Encontre e delete as "roles" que criamos para este projeto. As principais s√£o:
        * `AppRunnerInstanceRole`
        * `ECSTaskS3AppRunnerRole` (ou o nome que voc√™ deu)
        * A "role" do Step Functions (o nome come√ßa com `StepFunctions-Fut-BR-Retraining-Pipeline-role-...`)
        * A "role" do EventBridge (o nome come√ßa com `EventBridge-Trigger-Retraining-...`)
    * **Opcional:** Voc√™ tamb√©m pode deletar o usu√°rio `predictor-project-user` que criamos na Fase 1, se n√£o for mais utiliz√°-lo.

### Verifica√ß√£o Final

No dia seguinte, acesse o **AWS Billing Dashboard** e verifique no **Cost Explorer** se seus custos di√°rios voltaram a zero, confirmando que todos os recursos fatur√°veis foram removidos com sucesso.
