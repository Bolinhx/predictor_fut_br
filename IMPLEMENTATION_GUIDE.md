# Guia de Implementa√ß√£o: Pipeline MLOps Preditiva na AWS

Bem-vindo ao guia de implementa√ß√£o do projeto Predictor Fut BR! Este documento detalha o passo a passo para construir e implantar a arquitetura completa na sua pr√≥pria conta da AWS.

## üìã Pr√©-requisitos
Antes de come√ßar, garanta que voc√™ tenha:
1. Uma conta na AWS com acesso de administrador.

2. AWS CLI instalado e configurado em sua m√°quina local.

3. Docker Desktop instalado e rodando.

4. Python 3.11+ instalado.

5. Git instalado.

## ‚öôÔ∏è Fase 0: Configura√ß√£o Inicial do Projeto
Nesta fase, preparamos o ambiente local e as configura√ß√µes.

1. **Clonar o Reposit√≥rio:**
   ```bash
    git clone https://github.com/Bolinhx/predictor_fut_br.git
    cd predictor_fut_br
    ```
2. **Configurar Vari√°veis de Ambiente:**
   - Renomeie o arquivo .env.example para .env.
   - Abra o arquivo .env e preencha todas as vari√°veis com os valores da sua conta e recursos que ser√£o criados.
3. **Criar Ambiente Virtual e Instalar Depend√™ncias:**
   ```bash
   python -m venv venv
    source venv/bin/activate  # ou .\\venv\\Scripts\\activate no Windows
    pip install -r requirements.txt
    pip install -r ml_jobs/requirements-jobs.txt
    pip install -r frontend/requirements-frontend.txt
    ```

## üèóÔ∏è Fase 1: Funda√ß√£o da Infraestrutura na AWS
Nesta fase, criamos os recursos de base que nosso sistema precisar√° para armazenar dados e c√≥digo. N√£o vamos rodar nada ainda, apenas preparar o terreno.

1. **IAM - Usu√°rio Program√°tico:**
   Nunca usamos a conta "root" (principal) para tarefas do dia a dia ou para automa√ß√£o. O primeiro passo √© criar um usu√°rio dedicado com permiss√µes espec√≠ficas, seguindo o princ√≠pio do menor privil√©gio.

    1. Acesse o **Console da AWS** e procure pelo servi√ßo IAM.

    2. No menu lateral, clique em **Users** (Usu√°rios) e depois em Create user.

    3. **User details:**

   *  User name: D√™ um nome para o usu√°rio, por exemplo: predictor-project-user.

    *  N√ÉO marque a op√ß√£o "Provide user access to the AWS Management Console". Este usu√°rio ser√° usado apenas  1. por programas (acesso program√°tico).
    *  
    4. **Set permissions:**
   *   Selecione a op√ß√£o Attach policies directly.

   *   Na barra de busca, procure e marque as seguintes pol√≠ticas gerenciadas pela AWS. Elas dar√£o as permiss√µes necess√°rias para nossos servi√ßos interagirem:

       *   `AmazonS3FullAccess`

       *   `AmazonEC2ContainerRegistryFullAccess` (ou `AmazonECRFullAccess`)

       *   `AWSAppRunnerFullAccess`

       *   `AmazonECS_FullAccess`

       *   `AWSStepFunctionsFullAccess`
    5. **Review and create:**
   *   Revise as informa√ß√µes e clique em *Create user*.
    6. **Salve as Credenciais (Etapa Cr√≠tica):**
   *   Na lista de usu√°rios, clique no nome do usu√°rio que voc√™ acabou de criar.
   *   V√° para a aba **Security credentials**.
   *   Role para baixo at√© **Access keys** e clique em **Create access key.**
   *   Selecione **Command Line Interface (CLI)**, marque a caixa de confirma√ß√£o e clique em **Next**.
   *   Clique em **Create access key**.
   *   ***IMPORTANTE:*** Copie e salve o `Access key ID` e a `Secret access key` em um local seguro. Esta √© a √∫nica vez que a chave secreta ser√° exibida.
    7. **Configure a AWS CLI:**
   *   Abra seu terminal e configure o perfil de acesso com as chaves que voc√™ acabou de salvar:
        ```bash
        aws configure (ENTER)

        Preencha com seu Access Key ID, Secret Access Key, uma regi√£o padr√£o (ex: us-east-1) e o formato de sa√≠da (json).
        ```


2. **S3 - Criando nosso Bucket de Armazenamento (nosso "Data Lake")**
   O Amazon S3 ser√° o cora√ß√£o do nosso armazenamento, guardando os dados brutos, as features processadas e os modelos treinados.

   1. No console da AWS, procure e v√° para o servi√ßo **S3**.
   2. Clique em **Create bucket.**
   3. **General configuration:**
   *   **Bucket name:** D√™ um nome **globalmente √∫nico**. Use o padr√£o do seu arquivo `.env`: `predictor-fut-br-data-SEU-NOME-UNICO.`
   *   **AWS Region:** Selecione a mesma regi√£o que voc√™ configurou no seu AWS CLI.
   4. **Block Public Access settings:**
   *   Mantenha a op√ß√£o **Block all public access** LIGADA (marcada). Nossos dados s√£o privados.
   5. **Bucket Versioning:**
   *   Selecione **Enable.** Isso nos protege contra exclus√µes acidentais.
   6. **Default encryption:**
   *   Selecione **Enable**. Garanta que a op√ß√£o `Amazon S3-managed keys (SSE-S3)` esteja selecionada (esta op√ß√£o n√£o tem custo).
   7. **Clique em Create bucket.**

   8. **Crie as Pastas:**
   *   Dentro do bucket, clique em **Create folder** e crie as tr√™s pastas necess√°rias: `raw`, `processed` e `models`.
   9. **Fa√ßa o Upload do Dado Inicial:**
   *   Navegue at√© a pasta `raw` e fa√ßa o upload do arquivo `campeonato-brasileiro-full.csv` do seu computador.



3. **ECR - Criando os Reposit√≥rios para as Imagens Docker**
O Elastic Container Registry (ECR) √© o nosso "Docker Hub" privado na AWS, onde guardaremos as imagens prontas para serem usadas pelo App Runner e Fargate.

   1. No console da AWS, procure e v√° para o servi√ßo **Elastic Container Registry (ECR).**
   2. Clique em **Create repository.**
   3. Configure o primeiro reposit√≥rio:
   *   **Visibility settings**: `Private`
   *   **Repository name:** Use o nome que est√° no seu arquivo `.env`: `prediction-api` (ou o que voc√™ definiu).
   *   Clique em **Create repository.**
   4. **Repita o processo** para criar o segundo reposit√≥rio com o nome `ml-jobs`.
   


## üöÄ Fase 2: Deploy Manual e Valida√ß√£o
Nesta fase, vamos colocar nosso c√≥digo para rodar na nuvem pela primeira vez. O objetivo √© validar cada componente de forma isolada (as imagens Docker, as permiss√µes, os servi√ßos) antes de conect√°-los com a automa√ß√£o.

1. **Build e Push das Imagens Docker:**
   Nossas "receitas" (`Dockerfile`) est√£o prontas. Agora vamos us√°-las para construir as imagens e envi√°-las para nosso registro privado na AWS (ECR).

   1. **Autenticar o Docker no ECR:**
   No seu terminal, execute o comando abaixo, substituindo `sua-regiao` e `SEU_ID_DE_CONTA` pelos seus valores. A forma mais f√°cil de obter o comando exato √© ir ao console do **ECR**, clicar em um dos reposit√≥rios e no bot√£o **"View push commands".**
   ```bash
   aws ecr get-login-password --region sua-regiao | docker login --username AWS --password-stdin SEU_ID_DE_CONTA.dkr.sua-regiao.amazonaws.com
   ```
   Voc√™ deve ver a mensagem "Login Succeeded".

    2. **Construir, Marcar (Tag) e Enviar as Imagens:**
   Execute os seguintes comandos na raiz do seu projeto. Lembre-se de preencher as vari√°veis no seu arquivo `.env` primeiro, pois os comandos usam `$(grep ...)` para l√™-las. 
   *    **Para a API de Predi√ß√£o:**
        ```bash
        # Obter a URI do reposit√≥rio a partir do seu arquivo .env
        ECR_URI_API=$(grep ECR_REPO_API .env | cut -d '=' -f2 | tr -d '"')
        AWS_ACCOUNT_ID=$(grep AWS_ACCOUNT_ID .env | cut -d '=' -f2 | tr -d '"')
        AWS_REGION=$(grep AWS_REGION .env | cut -d '=' -f2 | tr -d '"')

        # Construir, marcar e enviar
        docker build -t $ECR_URI_API -f api/Dockerfile .
        docker tag $ECR_URI_API:latest $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_URI_API:latest
        docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_URI_API:latest
        ```




2. **Deploy da API no App Runner:**
   - WIP (Detalhe o processo de cria√ß√£o do servi√ßo no App Runner, a configura√ß√£o da porta, CPU/Mem√≥ria e, crucialmente, a cria√ß√£o da Instance Role para acesso ao S3).
   - WIP Solu√ß√£o de Problemas: Mencionar os erros comuns, como o timeout do Health Check e a necessidade de aumentar a mem√≥ria.
3. **Execu√ß√£o Manual dos Jobs no Fargate:**
   - WIP (Explicar como criar a Task Definition, a ECSTaskS3AccessRole e a ecsTaskExecutionRole. Mostre como executar a tarefa manualmente com o "Command Override" e como depurar os logs).
   - WIP (Solu√ß√£o de Problemas: Detalhar os erros de permiss√£o (iam:PassRole, AccessDenied) e como corrigi-los editando as pol√≠ticas do IAM.)

## ü§ñ Fase 3: Automa√ß√£o com a Pipeline MLOps
Agora, conectamos tudo em um fluxo autom√°tico.

1. **Cria√ß√£o da Pipeline no Step Functions:**
   - WIP (Mostrar como criar a State Machine visualmente, adicionando os tr√™s passos (ECS RunTask). Inclua os JSONs de configura√ß√£o para cada passo).
   - WIP Solu√ß√£o de Problemas: Explicar a import√¢ncia do .sync ("Wait for task to complete") e como depurar as permiss√µes da "role" do Step Functions.
2. **Cria√ß√£o do Gatilho no EventBridge:**
   - WIP (Mostrar como criar a regra, usando o JSON do "Event Pattern" para filtrar os eventos do S3. Explique a configura√ß√£o do alvo).
   - WIP Solu√ß√£o de Problemas: Destacar a necessidade de habilitar as "Event Notifications" nas propriedades do bucket S3.

## üñ•Ô∏è Fase 4: Frontend com Streamlit
A interface para o usu√°rio final.

1. **Teste Local:**
   - WIP (Explicar como rodar o streamlit run localmente para testar a interface).
1. **Deploy na Streamlit Community Cloud:**
   - WIP (Descrever o passo a passo para conectar o reposit√≥rio do GitHub ao Streamlit Cloud e fazer o deploy).

## üßπ Fase 5: Limpeza dos Recursos
Um guia essencial para evitar custos inesperados.

- WIP (Listar a ordem correta para deletar todos os recursos da AWS: App Runner, EventBridge, Step Functions, ECS, ECR, S3, IAM Roles).