# Guia de Implementa√ß√£o: Pipeline MLOps Preditiva na AWS

Bem-vindo ao guia de implementa√ß√£o do projeto Predictor Fut BR! Este documento detalha o passo a passo para construir e implantar a arquitetura completa na sua pr√≥pria conta da AWS.

## üìã Pr√©-requisitos
Antes de come√ßar, garanta que voc√™ tenha:
1. Uma conta na AWS com acesso de administrador.

2. AWS CLI instalado e configurado em sua m√°quina local.

3. Docker Desktop instalado e rodando.

4. Python 3.11+ instalado.

5. Git instalado.

## ‚öôÔ∏è Fase 0: Configura√ß√£o Inicial do Projeto
Nesta fase, preparamos o ambiente local e as configura√ß√µes.

1. **Clonar o Reposit√≥rio:**
   ```bash
    git clone https://github.com/Bolinhx/predictor_fut_br.git
    cd predictor_fut_br
    ```
2. **Configurar Vari√°veis de Ambiente:**
   - Renomeie o arquivo .env.example para .env.
   - Abra o arquivo .env e preencha todas as vari√°veis com os valores da sua conta e recursos que ser√£o criados.
3. **Criar Ambiente Virtual e Instalar Depend√™ncias:**
   ```bash
   python -m venv venv
    source venv/bin/activate  # ou .\\venv\\Scripts\\activate no Windows
    pip install -r requirements.txt
    pip install -r ml_jobs/requirements-jobs.txt
    pip install -r frontend/requirements-frontend.txt
    ```

## üèóÔ∏è Fase 1: Funda√ß√£o da Infraestrutura na AWS
Nesta fase, criamos os recursos de base que nosso sistema precisar√° para armazenar dados e c√≥digo. N√£o vamos rodar nada ainda, apenas preparar o terreno.

1. **IAM - Usu√°rio Program√°tico:**
   Nunca usamos a conta "root" (principal) para tarefas do dia a dia ou para automa√ß√£o. O primeiro passo √© criar um usu√°rio dedicado com permiss√µes espec√≠ficas, seguindo o princ√≠pio do menor privil√©gio.

    1. Acesse o **Console da AWS** e procure pelo servi√ßo IAM.

    2. No menu lateral, clique em **Users** (Usu√°rios) e depois em Create user.

    3. **User details:**

   *  User name: D√™ um nome para o usu√°rio, por exemplo: predictor-project-user.

    *  N√ÉO marque a op√ß√£o "Provide user access to the AWS Management Console". Este usu√°rio ser√° usado apenas  1. por programas (acesso program√°tico).
    *  
    4. **Set permissions:**
   *   Selecione a op√ß√£o Attach policies directly.

   *   Na barra de busca, procure e marque as seguintes pol√≠ticas gerenciadas pela AWS. Elas dar√£o as permiss√µes necess√°rias para nossos servi√ßos interagirem:

       *   `AmazonS3FullAccess`

       *   `AmazonEC2ContainerRegistryFullAccess` (ou `AmazonECRFullAccess`)

       *   `AWSAppRunnerFullAccess`

       *   `AmazonECS_FullAccess`

       *   `AWSStepFunctionsFullAccess`
    5. **Review and create:**
   *   Revise as informa√ß√µes e clique em *Create user*.
    6. **Salve as Credenciais (Etapa Cr√≠tica):**
   *   Na lista de usu√°rios, clique no nome do usu√°rio que voc√™ acabou de criar.
   *   V√° para a aba **Security credentials**.
   *   Role para baixo at√© **Access keys** e clique em **Create access key.**
   *   Selecione **Command Line Interface (CLI)**, marque a caixa de confirma√ß√£o e clique em **Next**.
   *   Clique em **Create access key**.
   *   ***IMPORTANTE:*** Copie e salve o `Access key ID` e a `Secret access key` em um local seguro. Esta √© a √∫nica vez que a chave secreta ser√° exibida.
    7. **Configure a AWS CLI:**
   *   Abra seu terminal e configure o perfil de acesso com as chaves que voc√™ acabou de salvar:
        ```bash
        aws configure (ENTER)

        Preencha com seu Access Key ID, Secret Access Key, uma regi√£o padr√£o (ex: us-east-1) e o formato de sa√≠da (json).
        ```

#

2. **S3 - Criando nosso Bucket de Armazenamento (nosso "Data Lake")**
   O Amazon S3 ser√° o cora√ß√£o do nosso armazenamento, guardando os dados brutos, as features processadas e os modelos treinados.

   1. No console da AWS, procure e v√° para o servi√ßo **S3**.
   2. Clique em **Create bucket.**
   3. **General configuration:**
   *   **Bucket name:** D√™ um nome **globalmente √∫nico**. Use o padr√£o do seu arquivo `.env`: `predictor-fut-br-data-SEU-NOME-UNICO.`
   *   **AWS Region:** Selecione a mesma regi√£o que voc√™ configurou no seu AWS CLI.
   4. **Block Public Access settings:**
   *   Mantenha a op√ß√£o **Block all public access** LIGADA (marcada). Nossos dados s√£o privados.
   5. **Bucket Versioning:**
   *   Selecione **Enable.** Isso nos protege contra exclus√µes acidentais.
   6. **Default encryption:**
   *   Selecione **Enable**. Garanta que a op√ß√£o `Amazon S3-managed keys (SSE-S3)` esteja selecionada (esta op√ß√£o n√£o tem custo).
   7. **Clique em Create bucket.**

   8. **Crie as Pastas:**
   *   Dentro do bucket, clique em **Create folder** e crie as tr√™s pastas necess√°rias: `raw`, `processed` e `models`.
   9. **Fa√ßa o Upload do Dado Inicial:**
   *   Navegue at√© a pasta `raw` e fa√ßa o upload do arquivo `campeonato-brasileiro-full.csv` do seu computador.
     
   <img width="2111" height="708" alt="S3 - Raiz" src="https://github.com/user-attachments/assets/11a625dc-de39-463a-a276-26fd0c7a6170" />


#

3. **ECR - Criando os Reposit√≥rios para as Imagens Docker**
O Elastic Container Registry (ECR) √© o nosso "Docker Hub" privado na AWS, onde guardaremos as imagens prontas para serem usadas pelo App Runner e Fargate.

   1. No console da AWS, procure e v√° para o servi√ßo **Elastic Container Registry (ECR).**
   2. Clique em **Create repository.**
   3. Configure o primeiro reposit√≥rio:
   *   **Visibility settings**: `Private`
   *   **Repository name:** Use o nome que est√° no seu arquivo `.env`: `prediction-api` (ou o que voc√™ definiu).
   *   Clique em **Create repository.**
   4. **Repita o processo** para criar o segundo reposit√≥rio com o nome `ml-jobs`.
   
   <img width="2116" height="822" alt="ECR-Repositorys" src="https://github.com/user-attachments/assets/df06fc01-99a4-466b-bd66-a919bfcef2d9" />

   

## üöÄ Fase 2: Deploy Manual e Valida√ß√£o
Nesta fase, vamos colocar nosso c√≥digo para rodar na nuvem pela primeira vez. O objetivo √© validar cada componente de forma isolada (as imagens Docker, as permiss√µes, os servi√ßos) antes de conect√°-los com a automa√ß√£o.

1. **Build e Push das Imagens Docker:**
   Nossas "receitas" (`Dockerfile`) est√£o prontas. Agora vamos us√°-las para construir as imagens e envi√°-las para nosso registro privado na AWS (ECR).

   1. **Autenticar o Docker no ECR:**
   No seu terminal, execute o comando abaixo, substituindo `sua-regiao` e `SEU_ID_DE_CONTA` pelos seus valores. A forma mais f√°cil de obter o comando exato √© ir ao console do **ECR**, clicar em um dos reposit√≥rios e no bot√£o **"View push commands".**
   ```bash
   aws ecr get-login-password --region sua-regiao | docker login --username AWS --password-stdin SEU_ID_DE_CONTA.dkr.sua-regiao.amazonaws.com
   ```
   Voc√™ deve ver a mensagem "Login Succeeded".

    2. **Construir, Marcar (Tag) e Enviar as Imagens:**
   Execute os seguintes comandos na raiz do seu projeto. Lembre-se de preencher as vari√°veis no seu arquivo `.env` primeiro, pois os comandos usam `$(grep ...)` para l√™-las. 
   *    **Para a API de Predi√ß√£o:**
        ```bash
        # Obter a URI do reposit√≥rio a partir do seu arquivo .env
        ECR_URI_API=$(grep ECR_REPO_API .env | cut -d '=' -f2 | tr -d '"')
        AWS_ACCOUNT_ID=$(grep AWS_ACCOUNT_ID .env | cut -d '=' -f2 | tr -d '"')
        AWS_REGION=$(grep AWS_REGION .env | cut -d '=' -f2 | tr -d '"')

        # Construir, marcar e enviar
        docker build -t $ECR_URI_API -f api/Dockerfile .
        docker tag $ECR_URI_API:latest $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_URI_API:latest
        docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_URI_API:latest
        ```
   *    **Para os Jobs de ML:**
        ```bash
        # Obter a URI do reposit√≥rio a partir do seu arquivo .env
        ECR_URI_JOBS=$(grep ECR_REPO_JOBS .env | cut -d '=' -f2 | tr -d '"')

        # Construir, marcar e enviar
        docker build -t $ECR_URI_JOBS -f ml_jobs/Dockerfile .
        docker tag $ECR_URI_JOBS:latest $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_URI_JOBS:latest
        docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_URI_JOBS:latest
        ```

#

2. **Deploy da API no App Runner:**
    Com a imagem da API no ECR, vamos coloc√°-la no ar.

    1. Acesse o servi√ßo **AWS App Runner** no console e clique em Create service
    2. **Source and deployment:**
*   **Source:** `Container registry`
*   **Container image registry:** `Amazon ECR`
*   **Container image URI:** `Container registry`
    3. **Configure service:**
*   **Service name:** `prediction-api`.
*   **Virtual CPU & memory:** Para testes, comece com `1 vCPU` e `2 GB`. Se a aplica√ß√£o falhar ao iniciar, pode ser necess√°rio aumentar a mem√≥ria para `3 GB`.
*   **Port:** `80`
    4. **Security (Etapa Crucial):**
*   Na se√ß√£o **Security**, clique em **Edit.**
*   **Instance role:** Para que a API possa acessar o S3, precisamos de uma permiss√£o. Crie uma nova IAM Role seguindo estes passos:
    *   **V√° para o IAM -> Roles -> Create role.**
    *   **Trusted entity type:** `Custom trust policy`. Cole o JSON:
        ```json
        {
        "Version": "2012-10-17",
        "Statement": [{
        "Effect": "Allow",
        "Principal": {"Service": "tasks.apprunner.amazonaws.com"},
        "Action": "sts:AssumeRole"
            }]
        }
        ```
    *   **Permissions:** Anexe a pol√≠tica gerenciada pela AWS `AmazonS3ReadOnlyAccess`.
    *   **Role name:** `AppRunnerInstanceRole.`
    *   Volte para a configura√ß√£o do App Runner, atualize a lista e selecione a `AppRunnerInstanceRole` que voc√™ acabou de criar.
    5. Clique em **Create & deploy**.

### ***üö® Solu√ß√£o de Problemas Comuns no App Runner***

*   Erro` Failed to create...`: Geralmente √© um problema de tempo ou mem√≥ria.
*   `Health check failed:` A aplica√ß√£o demorou muito para iniciar. Edite o servi√ßo, v√° em **Health check** e aumente os valores de Timeout (para `20s`) e Interval (para `25s`).
*   `Unable to locate credentials`: A **Instance role** n√£o foi criada ou anexada corretamente. Verifique o passo 4.


# 

3. **Execu√ß√£o Manual dos Jobs no Fargate:**
   Vamos validar que nossos scripts de processamento e treinamento rodam na nuvem.
    1. **Crie as Permiss√µes (IAM Roles)**: Nossa tarefa precisa de duas "credenciais":
*   **Task Execution Role:** Permiss√£o para o Fargate buscar a imagem no ECR. Geralmente a role `ecsTaskExecutionRole` j√° existe na conta.
*   **Task Role:** Permiss√£o para o nosso c√≥digo acessar outros servi√ßos.
    *   **V√° para IAM -> Roles -> Create role.**
    *   **Trusted entity:** `AWS service` -> **Use case**: `Elastic Container Service Task`.
    *   **Permissions**: Anexe as pol√≠ticas `AmazonS3FullAccess` e `AWSAppRunnerFullAccess`.
    *   **Role name:** `ECSTaskS3AppRunnerRole.`
    1. **Crie a Defini√ß√£o da Tarefa (Task Definition)**:
*   **V√° para Amazon ECS -> Task Definitions -> Create new task definition.**
*   **Task definition family**: `ml-job-task-family`.
*   **Launch type:** `AWS Fargate`.
*   **Task role:** Selecione a `ECSTaskS3AppRunnerRole` que acabamos de criar.
*   **Task execution role:** Selecione a `ecsTaskExecutionRole`.
*   **Container details:**
    *   **Name:** `ml-jobs-container`.
    *   **Image URI:** Cole a URI da sua imagem `ml-jobs` do ECR.
*   Clique em **Create**.
    1. **Execute a Tarefa Manualmente:**
*   V√° para **Amazon ECS** -> Clusters e selecione o cluster `default` (ou crie um novo do tipo "Networking only" se n√£o existir).
*   Clique na aba **Tasks -> Run new task.**
*   Launch type: `FARGATE`.
*   **Task definition:** Selecione a `ml-job-task-family`.
*   **Networking:** Garanta que uma VPC e Subnets estejam selecionadas e que **Public IP** esteja **ENABLED**.
*   **Container Overrides:** Expanda a se√ß√£o e, no campo **Command**, cole o comando para o primeiro script (separado por v√≠rgulas) NAO ESQUECE DE SUBSTITUIR O NOME DO SEU BUCKET!!!:
    ```bash
    python,data_processor.py,s3://SEU-BUCKET/raw/campeonato-brasileiro-full.csv,s3://SEU-BUCKET/raw/campeonato-brasileiro-full.csv,s3://SEU-BUCKET/processed/features.parquet
    ```
    (Nota: Para este teste, usamos o mesmo arquivo como hist√≥rico e "novo", o que funciona para valida√ß√£o).
*   Clique em **Run task**.

Se correr tudo bem, na pasta `processed` do seu bucket vai ter um arquivo com nome `features.parquet`

### ***üö® Solu√ß√£o de Problemas Comuns no Fargate***

*   **Erro** `iam:PassRole`: O servi√ßo que est√° executando a tarefa (Step Functions, no futuro)precisa     de permiss√£o para "entregar" a `Task Role` √† tarefa.
*   **Erro** `PermissionError`: `Forbidden`: A `Task Role` (`ECSTaskS3AppRunnerRole`) n√£o tem a    permiss√£o necess√°ria (ex: `AmazonS3FullAccess`).
*   **Erro** `FileNotFoundError`: `fsspec`: A imagem Docker est√° sem as bibliotecas `fsspec` e`s3fs`.  Adicione-as ao `ml_jobs/requirements-jobs.txt`.

# 


## ü§ñ Fase 3: Automa√ß√£o com a Pipeline MLOps
Agora, conectamos tudo em um fluxo autom√°tico.

1. **Cria√ß√£o da Pipeline no Step Functions:**
   - WIP (Mostrar como criar a State Machine visualmente, adicionando os tr√™s passos (ECS RunTask). Inclua os JSONs de configura√ß√£o para cada passo).
   - WIP Solu√ß√£o de Problemas: Explicar a import√¢ncia do .sync ("Wait for task to complete") e como depurar as permiss√µes da "role" do Step Functions.
2. **Cria√ß√£o do Gatilho no EventBridge:**
   - WIP (Mostrar como criar a regra, usando o JSON do "Event Pattern" para filtrar os eventos do S3. Explique a configura√ß√£o do alvo).
   - WIP Solu√ß√£o de Problemas: Destacar a necessidade de habilitar as "Event Notifications" nas propriedades do bucket S3.

## üñ•Ô∏è Fase 4: Frontend com Streamlit
A interface para o usu√°rio final.

1. **Teste Local:**
   - WIP (Explicar como rodar o streamlit run localmente para testar a interface).
1. **Deploy na Streamlit Community Cloud:**
   - WIP (Descrever o passo a passo para conectar o reposit√≥rio do GitHub ao Streamlit Cloud e fazer o deploy).

## üßπ Fase 5: Limpeza dos Recursos
Um guia essencial para evitar custos inesperados.

- WIP (Listar a ordem correta para deletar todos os recursos da AWS: App Runner, EventBridge, Step Functions, ECS, ECR, S3, IAM Roles).
